{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708158b5",
   "metadata": {},
   "source": [
    "# Wrangle Exercises\n",
    "Data Acquisition\n",
    "These exercises should go in a notebook or script named ```wrangle```. Add, commit, and push your changes.\n",
    "\n",
    "This exercise uses the ```cases```, ```dept```, and ```source``` tables from the ```311_data``` on the ```Codeup MySQL server```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3521ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "# The SparkSession is where you would specify the JDBC driver and additional connection details.\n",
    "# We'll use pd.read_sql to simplify here so we can focus on the Spark API and not the IT setup.\n",
    "# When using Spark on the job, you'll work with the operations team to install the right Java drivers and configure your connection\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ------------- #\n",
    "# Local Imports #\n",
    "# ------------- #\n",
    "\n",
    "# importing sys\n",
    "import sys\n",
    "\n",
    "# adding 00_helper_files to the system path\n",
    "sys.path.insert(0, '/Users/qmcbt/codeup-data-science/00_helper_files')\n",
    "\n",
    "# env containing sensitive access credentials\n",
    "import env\n",
    "from env import user, password, host\n",
    "from env import get_db_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ca7c2",
   "metadata": {},
   "source": [
    "## 1. Read the ```cases```, ```dept```, and ```source data``` into their own spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2a2b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------------+\n",
      "|index|source_id| source_username|\n",
      "+-----+---------+----------------+\n",
      "|    0|   100137|Merlene Blodgett|\n",
      "|    1|   103582|     Carmen Cura|\n",
      "|    2|   106463| Richard Sanchez|\n",
      "|    3|   119403|  Betty De Hoyos|\n",
      "|    4|   119555|  Socorro Quiara|\n",
      "+-----+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in source to a spark dataframe\n",
    "query = \"\"\"SELECT * FROM source\"\"\"\n",
    "url = get_db_url(\"311_data\")\n",
    "source_df = pd.read_sql(query, url)\n",
    "source_df = spark.createDataFrame(source_df)\n",
    "source_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f34b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 13:00:59 WARN TaskSetManager: Stage 3 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 13:01:04 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 3 (TID 3): Attempting to kill Python Worker\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|num_days_late|case_closed|   dept_division|service_request_type|   SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|1014127332|     1/1/18 0:42|    1/1/18 12:29|9/26/20 0:42|       NO| -998.5087616|        YES|Field Operations|        Stray Animal|      999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|               5|\n",
      "|1014127333|     1/1/18 0:46|     1/3/18 8:11| 1/5/18 8:30|       NO| -2.012604167|        YES|     Storm Water|Removal Of Obstru...|4.322222222|     Closed| svcCRMSS|2215  GOLIAD RD, ...|               3|\n",
      "|1014127334|     1/1/18 0:48|     1/2/18 7:57| 1/5/18 8:30|       NO| -3.022337963|        YES|     Storm Water|Removal Of Obstru...|4.320729167|     Closed| svcCRMSS|102  PALFREY ST W...|               3|\n",
      "|1014127335|     1/1/18 1:29|     1/2/18 8:13|1/17/18 8:30|       NO| -15.01148148|        YES|Code Enforcement|Front Or Side Yar...|16.29188657|     Closed| svcCRMSS|114  LA GARDE ST,...|               3|\n",
      "|1014127336|     1/1/18 1:34|    1/1/18 13:29| 1/1/18 4:34|      YES|  0.372164352|        YES|Field Operations|Animal Cruelty(Cr...|      0.125|     Closed| svcCRMSS|734  CLEARVIEW DR...|               7|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read in cases to a spark dataframe\n",
    "query = \"\"\"SELECT * FROM cases\"\"\"\n",
    "url = get_db_url(\"311_data\")\n",
    "cases_df = pd.read_sql(query, url)\n",
    "cases_df = spark.createDataFrame(cases_df)\n",
    "cases_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9cd27f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 16:45:48 WARN TaskSetManager: Stage 8 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 16:45:52 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 8 (TID 22): Attempting to kill Python Worker\n",
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 1/1/18 0:42          \n",
      " case_closed_date     | 1/1/18 12:29         \n",
      " SLA_due_date         | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " SLA_days             | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      "-RECORD 1------------------------------------\n",
      " case_id              | 1014127333           \n",
      " case_opened_date     | 1/1/18 0:46          \n",
      " case_closed_date     | 1/3/18 8:11          \n",
      " SLA_due_date         | 1/5/18 8:30          \n",
      " case_late            | NO                   \n",
      " num_days_late        | -2.012604167         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Storm Water          \n",
      " service_request_type | Removal Of Obstru... \n",
      " SLA_days             | 4.322222222          \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMSS             \n",
      " request_address      | 2215  GOLIAD RD, ... \n",
      " council_district     | 3                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:===========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cases_df.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f49275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "|       dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "|     311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|               Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|     Clean and Green|Parks and Recreation|    Parks & Recreation|                YES|\n",
      "|Clean and Green N...|Parks and Recreation|    Parks & Recreation|                YES|\n",
      "|    Code Enforcement|Code Enforcement ...|  DSD/Code Enforcement|                YES|\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in source to a spark dataframe\n",
    "query = \"\"\"SELECT * FROM dept\"\"\"\n",
    "url = get_db_url(\"311_data\")\n",
    "dept_df = pd.read_sql(query, url)\n",
    "dept_df = spark.createDataFrame(dept_df)\n",
    "dept_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e16f2",
   "metadata": {},
   "source": [
    "## 2. Let's see how writing to the local disk works in spark:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72995",
   "metadata": {},
   "source": [
    "* Write the code necessary to store the source data in both csv and json format, store these as ```sources_csv``` and ```sources_json```  \n",
    "### ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb26f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the .json file in a data folder overwriting any existing file with the same name\n",
    "source_df.write.json(\"data/source_json\", mode=\"overwrite\")\n",
    "\n",
    "# Write the .csv file in a data folder overwriting any existing file with the same name\n",
    "(\n",
    "    source_df.write.format(\"csv\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(\"data/source_csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4bd03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m.\u001b[m\u001b[m                         \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m        \u001b[34mdata\u001b[m\u001b[m\r\n",
      "\u001b[34m..\u001b[m\u001b[m                        NOTES_spark.ipynb         spark-wrangle.ipynb\r\n",
      "\u001b[34m.git\u001b[m\u001b[m                      NOTES_spark_wrangle.ipynb spark101.ipynb\r\n",
      ".gitignore                README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f627498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mmpg_csv\u001b[m\u001b[m     \u001b[34mmpg_json\u001b[m\u001b[m    \u001b[34msource_csv\u001b[m\u001b[m  \u001b[34msource_json\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92056ecd",
   "metadata": {},
   "source": [
    "* Inspect your folder structure. What do you notice?  \n",
    "### ANSWER: There is now a folder named data that was created when we initiated spark to createDataFrame; both the .json and .csv files are saved in that folder because we chose that directory in our code above with ```data/```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd0435",
   "metadata": {},
   "source": [
    "## 3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec74db4",
   "metadata": {},
   "source": [
    "#### source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ae846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " index           | 0                \n",
      " source_id       | 100137           \n",
      " source_username | Merlene Blodgett \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show in .T format\n",
    "source_df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f8d67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('index', LongType(), True), StructField('source_id', StringType(), True), StructField('source_username', StringType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .schema attribute shows the data types that Spark has inferred from the source\n",
    "source_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945a169",
   "metadata": {},
   "source": [
    "#### cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a42a9c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 16:52:08 WARN TaskSetManager: Stage 10 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 16:52:12 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 10 (TID 24): Attempting to kill Python Worker\n",
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 1/1/18 0:42          \n",
      " case_closed_date     | 1/1/18 12:29         \n",
      " SLA_due_date         | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " SLA_days             | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show in .T format\n",
    "cases_df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3192b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 16:58:33 WARN TaskSetManager: Stage 13 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 16:58:37 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 13 (TID 27): Attempting to kill Python Worker\n",
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 1/1/18 0:42          \n",
      " case_closed_date     | 1/1/18 12:29         \n",
      " case_due_date        | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " case_days            | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Rename Columns\n",
    "cases_df = cases_df.withColumnRenamed(\"SLA_due_date\", \"case_due_date\")\n",
    "cases_df = cases_df.withColumnRenamed('SLA_days', 'case_days')\n",
    "cases_df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91a2317e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('case_id', LongType(), True), StructField('case_opened_date', StringType(), True), StructField('case_closed_date', StringType(), True), StructField('case_due_date', StringType(), True), StructField('case_late', StringType(), True), StructField('num_days_late', DoubleType(), True), StructField('case_closed', StringType(), True), StructField('dept_division', StringType(), True), StructField('service_request_type', StringType(), True), StructField('case_days', DoubleType(), True), StructField('case_status', StringType(), True), StructField('source_id', StringType(), True), StructField('request_address', StringType(), True), StructField('council_district', LongType(), True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .schema attribute shows the data types that Spark has inferred from the source\n",
    "cases_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "370ad044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 17:52:40 WARN TaskSetManager: Stage 15 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 17:52:44 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 15 (TID 29): Attempting to kill Python Worker\n",
      "+-------------------+-------------------+-------------------+\n",
      "|   case_opened_date|      case_due_date|   case_closed_date|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2018-01-01 00:42:00|2020-09-26 00:42:00|2018-01-01 12:29:00|\n",
      "|2018-01-01 00:46:00|2018-01-05 08:30:00|2018-01-03 08:11:00|\n",
      "|2018-01-01 00:48:00|2018-01-05 08:30:00|2018-01-02 07:57:00|\n",
      "|2018-01-01 01:29:00|2018-01-17 08:30:00|2018-01-02 08:13:00|\n",
      "|2018-01-01 01:34:00|2018-01-01 04:34:00|2018-01-01 13:29:00|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# change columns from String to datetime\n",
    "# 'case_opened_date', 'case_closed_date', 'case_due_date'\n",
    "fmt = \"M/d/yy H:mm\"\n",
    "cases_df = (cases_df.withColumn(\"case_opened_date\", to_timestamp(\"case_opened_date\", fmt))\n",
    "            .withColumn(\"case_closed_date\", to_timestamp(\"case_closed_date\", fmt))\n",
    "            .withColumn(\"case_due_date\", to_timestamp(\"case_due_date\", fmt))\n",
    "           )\n",
    "cases_df.select(\"case_opened_date\", \"case_due_date\", \"case_closed_date\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58810c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:>                                                         (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 19:32:59 WARN TaskSetManager: Stage 16 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+\n",
      "|case_closed|case_late| count|\n",
      "+-----------+---------+------+\n",
      "|         NO|      YES|  6525|\n",
      "|        YES|      YES| 87978|\n",
      "|         NO|       NO| 11585|\n",
      "|        YES|       NO|735616|\n",
      "+-----------+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show count of every possible crosstab combination of values between case_closed and case_late\n",
    "cases_df.groupBy(\"case_closed\", \"case_late\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e516b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 0) / 8]\r",
      "\r",
      "[Stage 22:>                                                         (0 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/22 19:48:33 WARN TaskSetManager: Stage 22 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+\n",
      "|case_closed|case_late| count|\n",
      "+-----------+---------+------+\n",
      "|       true|    false|735616|\n",
      "|       true|     true| 87978|\n",
      "|      false|    false| 11585|\n",
      "|      false|     true|  6525|\n",
      "+-----------+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find the expression (expr) 'YES' and change it to 'True', all else is 'False'\n",
    "cases_df = cases_df.withColumn(\"case_closed\", expr('case_closed == \"YES\"')\n",
    "                              ).withColumn(\"case_late\", expr('case_late == \"YES\"'))\n",
    "\n",
    "cases_df.groupBy(\"case_closed\", \"case_late\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5826b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('case_id', LongType(), True), StructField('case_opened_date', TimestampType(), True), StructField('case_closed_date', TimestampType(), True), StructField('case_due_date', TimestampType(), True), StructField('case_late', BooleanType(), True), StructField('num_days_late', IntegerType(), True), StructField('case_closed', BooleanType(), True), StructField('dept_division', StringType(), True), StructField('service_request_type', StringType(), True), StructField('case_days', IntegerType(), True), StructField('case_status', StringType(), True), StructField('source_id', StringType(), True), StructField('request_address', StringType(), True), StructField('council_district', LongType(), True)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change data type to int\n",
    "# 'num_days_late', 'case_days'\n",
    "cases_df = cases_df.withColumn(\"num_days_late\", col(\"num_days_late\").cast(\"int\")\n",
    "                              ).withColumn(\"case_days\", col(\"case_days\").cast(\"int\"))\n",
    "\n",
    "cases_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98487c72",
   "metadata": {},
   "source": [
    "#### dept_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a6276ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " dept_division          | 311 Call Center  \n",
      " dept_name              | Customer Service \n",
      " standardized_dept_name | Customer Service \n",
      " dept_subject_to_SLA    | YES              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show in .T format\n",
    "dept_df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ec4319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dept_division', StringType(), True), StructField('dept_name', StringType(), True), StructField('standardized_dept_name', StringType(), True), StructField('dept_subject_to_SLA', StringType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .schema attribute shows the data types that Spark has inferred from the source\n",
    "dept_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e001127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 25:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|dept_subject_to_SLA|count|\n",
      "+-------------------+-----+\n",
      "|                YES|   31|\n",
      "|                 NO|    8|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dept_df.groupBy(\"dept_subject_to_SLA\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "362666e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|dept_subject_to_SLA|count|\n",
      "+-------------------+-----+\n",
      "|               true|   31|\n",
      "|              false|    8|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the expression (expr) 'YES' and change it to 'True', all else is 'False'\n",
    "dept_df = dept_df.withColumn(\"dept_subject_to_SLA\", expr('dept_subject_to_SLA == \"YES\"'))\n",
    "\n",
    "dept_df.groupBy(\"dept_subject_to_SLA\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d602f",
   "metadata": {},
   "source": [
    "### 1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604eacb2",
   "metadata": {},
   "source": [
    "### 2. How many Stray Animal cases are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf2813",
   "metadata": {},
   "source": [
    "### 3. How many service requests that are assigned to the Field Operations department (```dept_division```) are not classified as \"Officer Standby\" request type (```service_request_type```)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b42ad",
   "metadata": {},
   "source": [
    "### 4. Convert the ```council_district``` column to a ```string``` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02adbb",
   "metadata": {},
   "source": [
    "### 5. Extract the year from the ```case_closed_date``` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dcf8fe",
   "metadata": {},
   "source": [
    "### 6. Convert ```num_days_late``` from days to hours in new columns ```num_hours_late```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0ad45",
   "metadata": {},
   "source": [
    "### 7. Join the case data with the source and department data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eab21",
   "metadata": {},
   "source": [
    "### 8. Are there any cases that do not have a request source?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcec2e5",
   "metadata": {},
   "source": [
    "### 9. What are the top 10 service request types in terms of number of requests?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01dc07e",
   "metadata": {},
   "source": [
    "### 10. What are the top 10 service request types in terms of average days late?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddc8a0",
   "metadata": {},
   "source": [
    "### 11. Does number of days late depend on department?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc097a2e",
   "metadata": {},
   "source": [
    "### 12. How do number of days late depend on department and request type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b44bfc",
   "metadata": {},
   "source": [
    "## You might have noticed that the latest date in the dataset is fairly far off from the present day. To account for this, replace any occurances of the current time with the maximum date from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1cbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
